{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score, precision_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim import corpora, models\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "from pylab import get_cmap\n",
    "import seaborn\n",
    "\n",
    "from os import path, makedirs\n",
    "from itertools import combinations\n",
    "from re import sub, compile\n",
    "\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DVACH = '2ch'\n",
    "REDDIT = 'reddit'\n",
    "MTS = 'mts'\n",
    "\n",
    "DATA = REDDIT\n",
    "COMMENT = 'comment'\n",
    "if DATA == REDDIT:\n",
    "    LANG = 'en'\n",
    "else:\n",
    "    LANG = 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorizer import Vectorizer\n",
    "vc = Vectorizer(LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not path.exists('figures'):\n",
    "    makedirs('figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_plt_params():\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    seaborn.set_style('whitegrid')\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lda_model(texts):\n",
    "    texts = list(map(lambda text: vc.morph_sentence(text), texts))\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary, num_topics=1)\n",
    "    return lda\n",
    "\n",
    "def get_lda_topics(lda, num_topics):\n",
    "    r = compile(r'\\W+')\n",
    "    return [[sub(r, '', word.split('*')[1]) for word in topic[1].split(' + ')] \n",
    "          for topic in lda.print_topics(num_topics)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_CLASS = 'UNKNOWN'\n",
    "texts = np.array([])\n",
    "y = []\n",
    "references = []\n",
    "\n",
    "for class_id, name in enumerate([x for x in range(10)]):\n",
    "        df = DataFrame.from_csv(path.join('{}-topics/'.format(DATA), '{}.csv'.format(name)))\n",
    "        temp_texts = vc.make_vectors(df[COMMENT].values)\n",
    "        y += [class_id]*len(temp_texts)\n",
    "        if not texts.any():\n",
    "            texts = temp_texts\n",
    "        else:\n",
    "            texts = np.vstack((texts, temp_texts))\n",
    "        ldam = train_lda_model(df[COMMENT].values)\n",
    "        references.append(' '.join(get_lda_topics(ldam, 1)))\n",
    "        \n",
    "references = vc.make_vectors(references)\n",
    "X_train, X_test, y_train, _ = train_test_split(texts, y, test_size=0.1, random_state=42)\n",
    "\n",
    "df_an = DataFrame.from_csv(path.join('{}-topics/'.format(DATA), '{}.csv'.format(UNKNOWN_CLASS)))\n",
    "X_outliers = vc.make_vectors(df_an[COMMENT].values)\n",
    "X_test = X_test[:len(X_outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n",
    "regs = tsne_model.fit_transform(np.vstack([X_train,\n",
    "                                           X_test,\n",
    "                                           X_outliers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANGE = 23\n",
    "DOT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAADCCAYAAADq6ka8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff45e619e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_plt_params()\n",
    "\n",
    "for i in regs[:len(X_train)+len(X_test)]:\n",
    "    plt.scatter(i[0],i[1],color='black', s=DOT_SIZE)\n",
    "    \n",
    "for i in regs[len(X_train)+len(X_test):]:\n",
    "    plt.scatter(i[0],i[1],color='red', s=DOT_SIZE)\n",
    "    \n",
    "plt.xlim(-RANGE, RANGE)\n",
    "plt.ylim(-RANGE, RANGE)\n",
    "plt.plot()\n",
    "plt.savefig(path.join('figures', 'anomals.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StdThresholdClassifier():\n",
    "    def __init__(self, train, threshold=0.23, clf=LogisticRegression(C = 9)):\n",
    "        self._clf = clf\n",
    "        self._threshold = threshold\n",
    "        self._train = train\n",
    "        \n",
    "    def fit(self, X_train):\n",
    "         self._clf.fit(X_train, self._train)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return [1 if np.std(probs) < self._threshold else -1 for probs in self._clf.predict_proba(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CosineThresholdClassifier():\n",
    "    def __init__(self, threshold=0.5):\n",
    "        self._threshold = threshold\n",
    "                 \n",
    "    def _count_cosine(self, vector):\n",
    "        distances = [1 - cosine(vector, reference) for reference in references]\n",
    "        if all(distances) < self._threshold:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def fit(self, X_train):\n",
    "         pass\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return [self._count_cosine(vector) for vector in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "    def __init__(self, threshold=0.0004,  nb_epoch=50, encoding_dim=14, batch_size=32):\n",
    "        self._input_dim = 0\n",
    "        self._encoding_dim = encoding_dim\n",
    "        self._nb_epoch = nb_epoch\n",
    "        self._batch_size = batch_size\n",
    "        self._threshold = threshold\n",
    "        \n",
    "    def fit(self, X):\n",
    "        X_train, X_test = train_test_split(X, test_size=0.1)\n",
    "        self._input_dim = X_train.shape[1]\n",
    "        input_layer = Input(shape=(self._input_dim, ))\n",
    "        encoder = Dense(self._encoding_dim, activation='tanh', \n",
    "                        activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "        encoder = Dense(int(self._encoding_dim / 2), activation='relu')(encoder)\n",
    "        decoder = Dense(int(self._encoding_dim / 2), activation='tanh')(encoder)\n",
    "        decoder = Dense(self._input_dim, activation='relu')(decoder)\n",
    "        autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "        autoencoder.compile(optimizer='adam', \n",
    "                            loss='mean_squared_error', \n",
    "                            metrics=['accuracy'])\n",
    "        checkpointer = ModelCheckpoint(filepath='model.h5',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True)\n",
    "        tensorboard = TensorBoard(log_dir='./logs',\n",
    "                                  histogram_freq=0,\n",
    "                                  write_graph=True,\n",
    "                                  write_images=True)\n",
    "        history = autoencoder.fit(X_train, X_train,\n",
    "                            epochs=self._nb_epoch,\n",
    "                            batch_size=self._batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=(X_test, X_test),\n",
    "                            verbose=0,\n",
    "                            callbacks=[checkpointer, tensorboard]).history\n",
    "        self._autoencoder = load_model('model.h5')\n",
    "    \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = self._autoencoder.predict(X_test)\n",
    "        mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "        return [1 if x < self._threshold else -1 for x in mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM\n",
      "Accuracy on test=1.00, on anomals=0.00, overall=0.50\n",
      "\n",
      "IsolationForest\n",
      "Accuracy on test=0.10, on anomals=0.85, overall=0.47\n",
      "\n",
      "LocalOutlierFactor\n",
      "Accuracy on test=0.08, on anomals=0.87, overall=0.47\n",
      "\n",
      "STDThreshold\n",
      "Accuracy on test=0.53, on anomals=0.82, overall=0.68\n",
      "\n",
      "CosineThreshold\n",
      "Accuracy on test=0.00, on anomals=1.00, overall=0.50\n",
      "\n",
      "Autoencoder\n",
      "Accuracy on test=0.00, on anomals=1.00, overall=0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in [\n",
    "                    ('OneClassSVM', OneClassSVM(kernel='poly', nu=1e-4, gamma=1e-4)), \n",
    "                    ('IsolationForest', IsolationForest(n_estimators=10, bootstrap=False,random_state=0)),\n",
    "                    #('EllipticEnvelope', EllipticEnvelope(contamination=0.5, assume_centered=False, support_fraction=0.5)),\n",
    "                    ('LocalOutlierFactor', LocalOutlierFactor(n_neighbors=1, metric='cosine', algorithm='brute')),\n",
    "                    ('STDThreshold', StdThresholdClassifier(y_train, 0.2, LogisticRegression(C = 9))),\n",
    "                    ('CosineThreshold', CosineThresholdClassifier(0.3)),\n",
    "                    ('Autoencoder', Autoencoder(0.2, 50, 10, 10))\n",
    "                    ]:\n",
    "    clf = classifier\n",
    "    if classifier_name == 'LocalOutlierFactor':\n",
    "        y = clf.fit_predict(np.r_[X_train, X_test, X_outliers])\n",
    "        y_pred_train = y[:len(X_train)]\n",
    "        y_pred_test = y[len(X_train):len(X_train) + len(X_test)]\n",
    "        y_pred_outliers = y[len(X_train) + len(X_test):]\n",
    "    elif classifier_name == 'Autoencoder':\n",
    "        clf.fit(X_train)\n",
    "        y_pred_train = clf.predict(np.array(X_train))\n",
    "        y_pred_test = clf.predict(np.array(X_test))\n",
    "        y_pred_outliers = clf.predict(np.array(X_outliers))\n",
    "    else:\n",
    "        clf.fit(X_train)\n",
    "        y_pred_train = clf.predict(np.array(X_train))\n",
    "        y_pred_test = clf.predict(np.array(X_test))\n",
    "        y_pred_outliers = clf.predict(np.array(X_outliers))\n",
    "\n",
    "    print(classifier_name)\n",
    "    print('Accuracy on test={:0.2f}, on anomals={:0.2f}, overall={:0.2f}'.format(\n",
    "        accuracy_score(y_pred_test, np.negative(np.ones(shape=len(X_test)))),\n",
    "        accuracy_score(y_pred_outliers, np.ones(shape=len(y_pred_outliers))),\n",
    "        accuracy_score(np.hstack([y_pred_test, y_pred_outliers]),\n",
    "        np.hstack([np.negative(np.ones(shape=len(X_test))), \n",
    "                                   np.ones(shape=len(X_outliers))]))))\n",
    "    set_plt_params()\n",
    "    print()\n",
    "    [plt.scatter(i[0],i[1],color='black',s=DOT_SIZE) if y_pred_train[ind] == 1 else \n",
    "     plt.scatter(i[0],i[1],color='red', s=DOT_SIZE) for ind, i in enumerate(regs[:len(X_train)])]\n",
    "    [plt.scatter(i[0],i[1],color='black', s=DOT_SIZE) if y_pred_test[ind] == 1 else \n",
    "     plt.scatter(i[0],i[1],color='red', s=DOT_SIZE) for ind, i in enumerate(regs[len(X_train):len(X_train)+len(X_test)])]\n",
    "    [plt.scatter(i[0],i[1],color='black', s=DOT_SIZE) if y_pred_outliers[ind] == 1 else \n",
    "     plt.scatter(i[0],i[1],color='red', s=DOT_SIZE) for ind, i in enumerate(regs[len(X_train)+len(X_test):])]\n",
    "    plt.xlim(-RANGE, RANGE)\n",
    "    plt.ylim(-RANGE, RANGE)\n",
    "    plt.plot()\n",
    "    plt.savefig(path.join('figures', 'anomaly_on_{}.png').format(classifier_name.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM\n",
      "Accuracy on test=0.87, on anomals=0.19, overall=0.53\n",
      "\n",
      "IsolationForest\n",
      "Accuracy on test=0.08, on anomals=0.86, overall=0.47\n",
      "\n",
      "LocalOutlierFactor\n",
      "Accuracy on test=0.08, on anomals=0.87, overall=0.47\n",
      "\n",
      "STDThreshold\n",
      "Accuracy on test=0.82, on anomals=0.60, overall=0.71\n",
      "\n",
      "CosineThreshold\n",
      "Accuracy on test=0.00, on anomals=1.00, overall=0.50\n",
      "\n",
      "Autoencoder\n",
      "Accuracy on test=0.02, on anomals=0.98, overall=0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in [\n",
    "                    ('OneClassSVM', OneClassSVM(kernel='linear', nu=0.9, gamma=100)), \n",
    "                    ('IsolationForest', IsolationForest(n_estimators=60, bootstrap=True,random_state=0)),\n",
    "                    #('EllipticEnvelope', EllipticEnvelope(contamination=0.5, assume_centered=True, support_fraction=0.5)),\n",
    "                    ('LocalOutlierFactor', LocalOutlierFactor(n_neighbors=1, metric='cosine', algorithm='brute')),\n",
    "                    ('STDThreshold', StdThresholdClassifier(y_train, 0.15, LogisticRegression(C = 9))),\n",
    "                    ('CosineThreshold', CosineThresholdClassifier(0.2)),\n",
    "                    ('Autoencoder', Autoencoder(0.0088, 50, 50, 20))\n",
    "                    ]:\n",
    "    clf = classifier\n",
    "    if classifier_name == 'LocalOutlierFactor':\n",
    "        y = clf.fit_predict(np.r_[X_train, X_test, X_outliers])\n",
    "        y_pred_train = y[:len(X_train)]\n",
    "        y_pred_test = y[len(X_train):len(X_train) + len(X_test)]\n",
    "        y_pred_outliers = y[len(X_train) + len(X_test):]\n",
    "    else:\n",
    "        clf.fit(X_train)\n",
    "        y_pred_train = clf.predict(np.array(X_train))\n",
    "        y_pred_test = clf.predict(np.array(X_test))\n",
    "        y_pred_outliers = clf.predict(np.array(X_outliers))\n",
    "\n",
    "    print(classifier_name)\n",
    "    print('Accuracy on test={:0.2f}, on anomals={:0.2f}, overall={:0.2f}'.format(\n",
    "        accuracy_score(y_pred_test, np.negative(np.ones(shape=len(X_test)))),\n",
    "        accuracy_score(y_pred_outliers, np.ones(shape=len(y_pred_outliers))),\n",
    "        accuracy_score(np.hstack([y_pred_test, y_pred_outliers]),\n",
    "        np.hstack([np.negative(np.ones(shape=len(X_test))), \n",
    "                                   np.ones(shape=len(X_outliers))]))))\n",
    "    set_plt_params()\n",
    "    print()\n",
    "    [plt.scatter(i[0],i[1],color='black',s=DOT_SIZE) if y_pred_train[ind] == 1 else \n",
    "     plt.scatter(i[0],i[1],color='red', s=DOT_SIZE) for ind, i in enumerate(regs[:len(X_train)])]\n",
    "    [plt.scatter(i[0],i[1],color='black', s=DOT_SIZE) if y_pred_test[ind] == 1 else \n",
    "     plt.scatter(i[0],i[1],color='red', s=DOT_SIZE) for ind, i in enumerate(regs[len(X_train):len(X_train)+len(X_test)])]\n",
    "    [plt.scatter(i[0],i[1],color='black', s=DOT_SIZE) if y_pred_outliers[ind] == 1 else \n",
    "     plt.scatter(i[0],i[1],color='red', s=DOT_SIZE) for ind, i in enumerate(regs[len(X_train)+len(X_test):])]\n",
    "    plt.xlim(-RANGE, RANGE)\n",
    "    plt.ylim(-RANGE, RANGE)\n",
    "    plt.plot()\n",
    "    plt.savefig(path.join('figures', 'anomaly_on_{}.png').format(classifier_name.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma_range = np.arange(0.5, 5, 0.1)\n",
    "nu_range = np.arange(1e-2, 0.3, 1e-2)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma':  gamma_range,\n",
    "                    'nu': nu_range},\n",
    "                   ]\n",
    "\n",
    "clf = GridSearchCV(OneClassSVM(), tuned_parameters, \n",
    "                    scoring=(lambda estimator, train_set, target_set: \n",
    "                    accuracy_score(estimator.fit(train_set).predict(texts_reg_test + \n",
    "                                                                   texts_anomal), \n",
    "                    np.hstack([np.negative(np.ones(shape=len(texts_reg_test))), \n",
    "                               np.ones(shape=len(texts_anomal))]))))\n",
    "\n",
    "print('Grid scores:')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print('{:0.3f} (+/-{:0.03f} for {})'.format(mean, std*2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = clf.cv_results_['mean_test_score'].reshape(len(nu_range), \n",
    "                                                       len(gamma_range))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=get_cmap(\"Spectral\"),\n",
    "           norm=MidpointNormalize(vmin=0.5, midpoint=0.6))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('nu')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(nu_range)), nu_range)\n",
    "#plt.title('Gridsearch Heatmap on RBF Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
